Тестовое задание: Парсинг Avito и веб-интерфейс для загрузки XML
---
Этот проект представляет собой решение тестового задания для Python-разработчика, включающего парсинг данных с Avito и интеграцию с веб-интерфейсом для загрузки XML-файлов.

Установка
---
1. Создайте новую папку и откройте её в IDE.
2. Откройте консоль и введите:
```bash
git clone https://github.com/MikhailYablokov/Avito-Parser.git .
```
3. После введите:
```bash
pip install -r requirements.txt
```
4. Для запуска парсера необходимо ввести в консоль:
```bash
python parser_avito.py
```
- Процесс работы приложения:
![image](https://github.com/user-attachments/assets/d22b67f7-a0ef-4120-b419-04f76e67a9fb)

5. Для запуска простого веб-интерфейса для загрузкии XML-файлов введите в консоль:
```bash
uvicorn main:app --reload
```
6. После чего введите в строку поиска в браузере http://127.0.0.1:8000
![image](https://github.com/user-attachments/assets/d6762fd2-939b-4d3e-90e6-847243e63e1e)
![image](https://github.com/user-attachments/assets/013e140d-ef4a-4643-bd02-f691520fe2ee)
 
## Описание проекта

Проект состоит из двух основных частей:
1. **Парсер Avito** (`parser_avito.py`) — скрипт для сбора данных о недвижимости в ЮФО с сайта Avito.
2. **Веб-приложение** (`main.py`) — FastAPI-приложение с веб-интерфейсом для загрузки XML-файлов и проверки уникальности объявлений.

### Задача 1: Парсинг данных с Avito
- **Цель**: Сбор объявлений о продаже квартир в регионах ЮФО.
- **Поля**: Заголовок, цена, адрес, площадь (м²), ссылка, дата публикации.
- **Выходной формат**: XML-файлы с именем `avito_{region}_{годмесяцдень_часыминуты}.xml`.
- **Особенности**:
  - Используется библиотека `seleniumbase` для парсинга динамического контента.
  - Обработка ошибок (таймауты, ограничение доступа).
  - Сохранение данных по 2000 объявления в файл.

### Задача 2: Интеграция XML с веб-интерфейсом
- **Цель**: Загрузка XML-файлов через веб-интерфейс с проверкой дубликатов.
- **Технологии**: FastAPI, Jinja2, HTML.
- **Проверка уникальности**: Объявления считаются дубликатами, если совпадают URL или комбинация заголовка и адреса.
- **Интерфейс**: Простая HTML-форма с отображением статуса загрузки.

## Как запустить проект
### Требования
- Python 3.8+
- Установленные зависимости: `pip install -r requirements.txt`
  - fastapi
  - uvicorn
  - jinja2
  - seleniumbase
  - loguru

Структура проекта
---
```
project_root/
├── static/              # Статические файлы (CSS, JS)
├── templates/           # HTML-шаблоны
│   └── upload_form.html # Форма загрузки
|   └── upload.html
├── main.py              # FastAPI-приложение
├── avito_parser.py      # Парсер Avito
├── ads.json             # Хранилище загруженных объявлений
└── README.md            # Документация
```

## Задача 4: Легаси-код
**1. Какие проблемы вы видите в этом коде?**
- Нет обработки ошибок
- Нет проверки дупликатов
- Нет оптимизации оперативной памяти для работы с большими файлами
- Нет валидации данных
- Жесткая привязка к структуре

**2. Как бы вы модифицировали его для работы с Python-скриптом?**
- Переписал бы код на python как в parser_avito.py

**3. Предложите решение для увеличения производительности при загрузке 10k+ объявлений**
- Переписать на python с использованием параллельной обработки
- Потоковая обработка XML: Вместо того, чтобы загружать весь файл в память, можно использовать потоковое чтение данных с помощью библиотеки xml.etree.ElementTree. Это позволяет обрабатывать XML-файл по частям, уменьшая нагрузку на память.

## Задача 3: 
- Реализована: смотрите pull request на github
  
Какие проблемы могли возникнуть при парсинге Avito и как их решить.
---
- Проблемы парсинга Avito из-за противодействия платформы:
- 
Динамический контент: JavaScript подгружает данные, что делает BeautifulSoup бесполезным без рендеринга.
Блокировка запросов: Защита (Cloudflare, частота запросов) банит HTTP-клиенты, требуя сложных "костылей" (прокси, User-Agent).
Ограничения IP: Частые запросы с одного IP приводят к бану, как видно в проверке "Доступ ограничен".
Stale Elements и CAPTCHA: DOM-обновления ломают Selenium, а CAPTCHA требует доп. решений.
Selenium vs BeautifulSoup: Selenium медленный, но обходит JS и эмулирует пользователя. BeautifulSoup быстрее, но нестабилен без прокси и обхода блокировок.
